# ğŸ”¥ Benchmark NoSQL Multi-ModÃ¨le

Comparaison de performance entre **MongoDB**, **Redis**, **Cassandra** et **Neo4j** sur diffÃ©rents cas d'usage.

---

## ğŸ“‹ ScÃ©narios testÃ©s

| ScÃ©nario | Description | Meilleur DB attendu |
| :--- | :--- | :--- |
| 1. CRUD | INSERT/READ/UPDATE/DELETE basiques | MongoDB, Redis |
| 2. IoT/Logs | DonnÃ©es massives haute frÃ©quence | Cassandra |
| 3. Graphes | Relations et traversÃ©es | Neo4j |
| 4. Key-Value | GET/SET ultra rapides | Redis |
| 5. Full-Text | Recherche textuelle | MongoDB |
| 6. ScalabilitÃ© | Multi-threading | Redis, Cassandra |

Pour chaque scÃ©nario, on exÃ©cute le mÃªme test sur les 4 bases et on mesure :
*   â±ï¸ Temps dâ€™exÃ©cution total
*   ğŸ”„ Latence par opÃ©ration
*   ğŸ’» CPU utilisÃ©
*   ğŸ§  MÃ©moire utilisÃ©e
*   ğŸ“‚ I/O (lecture/Ã©criture)

---

## ğŸ”¥ ScÃ©narios dÃ©taillÃ©s

### ğŸŸ© ScÃ©nario 1 â€” CRUD Simple
**Objectif** : Tester les opÃ©rations basiques (INSERT, READ, UPDATE, DELETE).
*   **DonnÃ©es utilisÃ©es (JSON simple)** :
    ```json
    {
      "user_id": 1,
      "name": "Test User",
      "age": 25,
      "city": "Paris"
    }
    ```
*   **Tests** : 100k INSERT, 100k READ, 100k UPDATE, 100k DELETE.
*   **Conclusion attendue** :
    *   **MongoDB** : TrÃ¨s bon
    *   **Redis** : Excellent (en mÃ©moire)
    *   **Cassandra** : Lent en UPDATE mais rapide en INSERT
    *   **Neo4j** : Pas adaptÃ©

| Champ | Signification |
| :--- | :--- |
| `write_time` | Temps total dâ€™Ã©criture |
| `write_latency_ms` | Latence moyenne dâ€™Ã©criture |
| `read_time` | Temps total de lecture |
| `read_latency_ms` | Latence moyenne de lecture |
| `cpu_usage` | CPU utilisÃ©e |
| `ram_usage` | RAM utilisÃ©e |

### ğŸŸ¦ ScÃ©nario 2 â€” IoT / Logs
**Objectif** : Simuler des donnÃ©es massives haute frÃ©quence (ex: capteurs).
*   **DonnÃ©es** :
    ```json
    {
      "sensor_id": "A12",
      "timestamp": "2025-12-03 18:01:00",
      "temperature": 25.4,
      "humidity": 64
    }
    ```
*   **Tests** : Insertion batch, lecture par plage de timestamps, indexation.
*   **Conclusion attendue** : Cassandra > MongoDB (avec index) > Redis > Neo4j

| Champ | Signification |
| :--- | :--- |
| `insert_time` | Temps dâ€™insertion des donnÃ©es |
| `insert_throughput` | DÃ©bit dâ€™insertion (records/sec) |
| `insert_cpu` | CPU utilisÃ©e pour insertion |
| `insert_mem` | RAM utilisÃ©e |
| `index_time` | Temps pour crÃ©er index (MongoDB) |
| `range_query_time` | Temps pour requÃªte sur intervalle |
| `records_found` | Nombre dâ€™enregistrements retrouvÃ©s |

### ğŸŸ¥ ScÃ©nario 3 â€” Graph Social
**Objectif** : Tester les relations et requÃªtes complexes dans un graphe.
*   **DonnÃ©es** : Utilisateurs + relations `friend_of` et `likes`.
*   **Tests** : Amis dâ€™un ami, connexions sur 3 niveaux, communautÃ©s.
*   **Conclusion attendue** : Neo4j > RedisGraph (optionnel) > MongoDB/Cassandra

| Champ | Signification |
| :--- | :--- |
| `create_users_time` | CrÃ©ation des utilisateurs |
| `create_friendships_time` | CrÃ©ation des relations |
| `friends_of_friends_time` | Temps requÃªte "amis des amis" |
| `three_level_time` | Temps requÃªte profondeur 3 |
| `records_inserted` | Nombre de nÅ“uds insÃ©rÃ©s |
| `records_found` | RÃ©sultats retournÃ©s |

### ğŸŸ§ ScÃ©nario 4 â€” Key-Value Haute Performance
**Objectif** : Tester la rapiditÃ© pour SET/GET.
*   **DonnÃ©es** : ClÃ©s â†’ Valeurs simples (session, token).
*   **Tests** : 100k SET, 100k GET, expiration TTL.
*   **Conclusion attendue** : Redis imbattable.

| Champ | Signification |
| :--- | :--- |
| `set_latency_ms` | Temps pour SET |
| `get_latency_ms` | Temps pour GET |
| `throughput_ops` | OpÃ©rations/sec |
| `cpu_usage` | CPU utilisÃ©e |
| `ram_usage` | RAM utilisÃ©e |
| `memory_used_mb` | RAM totale Redis |

### ğŸŸª ScÃ©nario 5 â€” Recherche Textuelle
**Objectif** : Tester les recherches full-text.
*   **DonnÃ©es** : 100k articles (titre, contenu, tags).
*   **Tests** : Recherche par mot-clÃ©, multi-mots, tri par pertinence.
*   **Conclusion attendue** : MongoDB > Redis (RedisSearch) > Cassandra/Neo4j.

| Champ | Signification |
| :--- | :--- |
| `insert_time` | DurÃ©e dâ€™insertion des documents |
| `index_build_time` | Temps pour construire index texte |
| `search_latency` | Temps pour rechercher |
| `top_k_results` | Documents trouvÃ©s |
| `cpu_usage` | CPU pendant index/recherche |
| `ram_usage` | RAM utilisÃ©e |

### ğŸŸ« ScÃ©nario 6 â€” ScalabilitÃ© Multi-ModÃ¨le
**Objectif** : Tester le comportement en montÃ©e en charge et opÃ©rations combinÃ©es.
*   **Tests** : Multi-threading (5,10,50,100), insert + read simultanÃ©s.
*   **Conclusion attendue** : Cassandra > Redis > MongoDB > Neo4j.

| Champ | Signification |
| :--- | :--- |
| `create_time` | Temps crÃ©ation donnÃ©es |
| `read_time` | Temps lecture donnÃ©es |
| `update_time` | Temps mise Ã  jour |
| `delete_time` | Temps suppression |
| `complex_query_time` | Temps requÃªte complexe |
| `cpu_total` | CPU totale utilisÃ©e |
| `ram_total` | RAM totale utilisÃ©e |
| `throughput_ops` | Ops/sec totales |

---

## ğŸ¯ RÃ©sumÃ© simple

| ScÃ©nario | Description |
| :--- | :--- |
| 1. CRUD Simple | Lecture/Ã©criture basique |
| 2. IoT / Time-Series | Insertion massive + requÃªtes par intervalle |
| 3. Social Graph | NÅ“uds + relations + requÃªtes profondes |
| 4. Key-Value Haute Vitesse | SET/GET grande Ã©chelle |
| 5. Recherche Textuelle | Indexation + recherche full-text |
| 6. Benchmark Global | CRUD + requÃªtes complexes + analyse |

---

## ğŸš€ Installation rapide

```bash
git clone <url>
cd benchmark-nosql
pip install -r requirements.txt
cd docker
docker-compose up -d
docker ps
```

## â–¶ï¸ ExÃ©cution

```bash
# Tous les scÃ©narios
python run_all_benchmarks.py

# ScÃ©nario spÃ©cifique
python scenario1_crud_benchmark.py
python scenario2_iot_logs.py

```

## ğŸ“Š Visualisation des rÃ©sultats

**Grafana** : [http://localhost:3000](http://localhost:3000) (admin / admin)

**InfluxDB** : [http://localhost:8086](http://localhost:8086) (Org: ensa, Bucket: bench)

**Exemple de requÃªte InfluxDB :**

```flux
from(bucket: "bench")
  |> range(start: -1h)
  |> filter(fn: (r) => r["_measurement"] == "scenario1_crud")
  |> filter(fn: (r) => r["_field"] == "latency_ms")
  |> group(columns: ["database", "operation"])
```

## ğŸ›‘ ArrÃªter le projet
```bash
docker-compose down       # arrÃªter les conteneurs
docker-compose down -v    # supprimer tout (volumes inclus)
```
## ğŸ“ RÃ©sultats attendus par DB
| DB | Excellent | Moyen |
| :--- | :--- | :--- |
| **MongoDB** ğŸ”µ | CRUD, Full-Text, IoT (index) | Graphes, ScalabilitÃ© |
| **Redis** ğŸ”´ | Key-Value, ScalabilitÃ©, CRUD lecture | Full-Text (sans RedisSearch), Graphes |
| **Cassandra** ğŸŸ£ | IoT/Logs, ScalabilitÃ© | UPDATE, Graphes, Full-Text |
| **Neo4j** ğŸŸ¢ | Graphes complexes | CRUD simples, Key-Value, IoT, ScalabilitÃ© |

##  ProblÃ¨mes courants

- **Cassandra lent au dÃ©marrage** â†’ `docker logs cassandra`
- **Erreur connexion InfluxDB** â†’ vÃ©rifier le token et `docker ps`
- **Module Python manquant** â†’ `pip install -r requirements.txt`

## ğŸ‘¨â€ğŸ’» Auteurs

- **Ahlam** - Configuration Docker
- **Ilham** - Configuration Docker et tests Benchmark
- **Lina Ait Ider** - Analyse de donnÃ©es et Visualisation Grafana

