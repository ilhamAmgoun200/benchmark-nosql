ğŸ”¥ Benchmark NoSQL Multi-ModÃ¨le

Comparaison de performance entre MongoDB, Redis, Cassandra et Neo4j sur diffÃ©rents cas d'usage.

ğŸ“‹ ScÃ©narios testÃ©s
ScÃ©nario	Description	Meilleur DB attendu
1. CRUD	INSERT/READ/UPDATE/DELETE basiques	MongoDB, Redis
2. IoT/Logs	DonnÃ©es massives haute frÃ©quence	Cassandra
3. Graphes	Relations et traversÃ©es	Neo4j
4. Key-Value	GET/SET ultra rapides	Redis
5. Full-Text	Recherche textuelle	MongoDB
6. ScalabilitÃ©	Multi-threading	Redis, Cassandra

Pour chaque scÃ©nario, on exÃ©cute le mÃªme test sur les 4 bases et on mesure :

â±ï¸ Temps dâ€™exÃ©cution total

ğŸ”„ Latence par opÃ©ration

ğŸ’» CPU utilisÃ©

ğŸ§  MÃ©moire utilisÃ©e

ğŸ“‚ I/O (lecture/Ã©criture)

ğŸ”¥ ScÃ©narios dÃ©taillÃ©s
ğŸŸ© ScÃ©nario 1 â€” CRUD Simple

Objectif : tester les opÃ©rations basiques (INSERT, READ, UPDATE, DELETE).
DonnÃ©es utilisÃ©es (JSON simple) :

{
  "user_id": 1,
  "name": "Test User",
  "age": 25,
  "city": "Paris"
}


Tests : 100k INSERT, 100k READ, 100k UPDATE, 100k DELETE
Conclusion attendue :

MongoDB : trÃ¨s bon

Redis : excellent (en mÃ©moire)

Cassandra : lent en UPDATE mais rapide en INSERT

Neo4j : pas adaptÃ©

Champs mesurÃ©s :

Champ	Signification
write_time	Temps total dâ€™Ã©criture
write_latency_ms	Latence moyenne dâ€™Ã©criture
read_time	Temps total de lecture
read_latency_ms	Latence moyenne de lecture
cpu_usage	CPU utilisÃ©e
ram_usage	RAM utilisÃ©e
ğŸŸ¦ ScÃ©nario 2 â€” IoT / Logs

Objectif : simuler des donnÃ©es massives haute frÃ©quence (ex: capteurs).
DonnÃ©es :

{
  "sensor_id": "A12",
  "timestamp": "2025-12-03 18:01:00",
  "temperature": 25.4,
  "humidity": 64
}


Tests : insertion batch, lecture par plage de timestamps, indexation
Conclusion attendue : Cassandra > MongoDB (avec index) > Redis > Neo4j

Champs mesurÃ©s :

Champ	Signification
insert_time	Temps dâ€™insertion des donnÃ©es
insert_throughput	DÃ©bit dâ€™insertion (records/sec)
insert_cpu	CPU utilisÃ©e pour insertion
insert_mem	RAM utilisÃ©e
index_time	Temps pour crÃ©er index (MongoDB)
range_query_time	Temps pour exÃ©cuter une requÃªte sur intervalle
records_found	Nombre dâ€™enregistrements retrouvÃ©s
ğŸŸ¥ ScÃ©nario 3 â€” Graph Social

Objectif : tester les relations et requÃªtes complexes dans un graphe.
DonnÃ©es : utilisateurs + relations friend_of et likes
Tests : amis dâ€™un ami, connexions sur 3 niveaux, communautÃ©s
Conclusion attendue : Neo4j > RedisGraph (optionnel) > MongoDB/Cassandra

Champs mesurÃ©s :

Champ	Signification
create_users_time	CrÃ©ation des utilisateurs
create_friendships_time	CrÃ©ation des relations
friends_of_friends_time	Temps requÃªte amis des amis
three_level_time	Temps requÃªte profondeur 3
records_inserted	Nombre de nÅ“uds insÃ©rÃ©s
records_found	RÃ©sultats retournÃ©s
ğŸŸ§ ScÃ©nario 4 â€” Key-Value Haute Performance

Objectif : tester la rapiditÃ© pour SET/GET
DonnÃ©es : clÃ©s â†’ valeurs simples (session, token)
Tests : 100k SET, 100k GET, expiration TTL
Conclusion attendue : Redis imbattable

Champs mesurÃ©s :

Champ	Signification
set_latency_ms	Temps pour SET
get_latency_ms	Temps pour GET
throughput_ops	OpÃ©rations/sec
cpu_usage	CPU utilisÃ©e
ram_usage	RAM utilisÃ©e
memory_used_mb	RAM totale Redis
ğŸŸª ScÃ©nario 5 â€” Recherche Textuelle

Objectif : tester les recherches full-text
DonnÃ©es : 100k articles (titre, contenu, tags)
Tests : recherche par mot-clÃ©, multi-mots, tri par pertinence
Conclusion attendue : MongoDB > Redis (RedisSearch) > Cassandra/Neo4j

Champs mesurÃ©s :

Champ	Signification
insert_time	DurÃ©e dâ€™insertion des documents
index_build_time	Temps pour construire index texte
search_latency	Temps pour rechercher
top_k_results	Documents trouvÃ©s
cpu_usage	CPU pendant index/recherche
ram_usage	RAM utilisÃ©e
ğŸŸ« ScÃ©nario 6 â€” ScalabilitÃ© Multi-ModÃ¨le

Objectif : tester le comportement en montÃ©e en charge et opÃ©rations combinÃ©es
Tests : multi-threading (5,10,50,100), insert + read simultanÃ©s
Conclusion attendue : Cassandra > Redis > MongoDB > Neo4j

Champs mesurÃ©s :

Champ	Signification
create_time	Temps crÃ©ation donnÃ©es
read_time	Temps lecture donnÃ©es
update_time	Temps mise Ã  jour
delete_time	Temps suppression
complex_query_time	Temps requÃªte complexe
cpu_total	CPU totale utilisÃ©e
ram_total	RAM totale utilisÃ©e
throughput_ops	Ops/sec totales
ğŸ¯ RÃ©sumÃ© simple
ScÃ©nario	Description
1. CRUD Simple	Lecture/Ã©criture basique
2. IoT / Time-Series	Insertion massive + range queries
3. Social Graph	NÅ“uds + relations + requÃªtes profondes
4. Key-Value Haute Vitesse	SET/GET grande Ã©chelle
5. Recherche Textuelle	Indexation + recherche full-text
6. Benchmark Global	CRUD + requÃªtes complexes + analyse
ğŸš€ Installation rapide
git clone <url>
cd benchmark-nosql
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate      # Windows
pip install pymongo redis neo4j-driver influxdb-client psutil
docker-compose up -d
docker ps  # VÃ©rifier que tout tourne

â–¶ï¸ ExÃ©cution
# Tous les scÃ©narios
python run_all_benchmarks.py

# ScÃ©nario spÃ©cifique
python scenario1_crud_benchmark.py
python scenario2_iot_logs.py

ğŸ“Š Visualisation des rÃ©sultats

Grafana : http://localhost:3000
 (admin / admin)

InfluxDB : http://localhost:8086
 (Org: ensa, Bucket: bench)

Exemple query InfluxDB :

from(bucket: "bench")
  |> range(start: -1h)
  |> filter(fn: (r) => r["_measurement"] == "scenario1_crud")
  |> filter(fn: (r) => r["_field"] == "latency_ms")
  |> group(columns: ["database", "operation"])

ğŸ›‘ ArrÃªter le projet
docker-compose down       # arrÃªter conteneurs
docker-compose down -v    # supprimer tout (volumes inclus)

ğŸ“ RÃ©sultats attendus par DB
DB	Excellent	Moyen
MongoDB ğŸ”µ	CRUD, Full-Text, IoT (index)	Graphes, ScalabilitÃ©
Redis ğŸ”´	Key-Value, ScalabilitÃ©, CRUD lecture	Full-Text (sans RedisSearch), Graphes
Cassandra ğŸŸ£	IoT/Logs, ScalabilitÃ©	UPDATE, Graphes, Full-Text
Neo4j ğŸŸ¢	Graphes complexes	CRUD simples, Key-Value, IoT, ScalabilitÃ©
ğŸ› ProblÃ¨mes courants

Cassandra lent au dÃ©marrage â†’ docker logs cassandra

Erreur connexion InfluxDB â†’ vÃ©rifier token et conteneur docker ps

Module Python manquant â†’ pip install -r requirements.txt

ğŸ‘¨â€ğŸ’» Auteur

Projet de benchmark NoSQL - ENSA 2025